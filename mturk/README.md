# Mechanical Turk Evaluation Data

`_main.csv` files: Results of evaluating items flagged via each method tested, and supply Tables 3, 8, 9 and Figure 6. For Amazon, not all items that are flagged are sent for evaluation, as we match the baseline protocol of [Northcutt et al., 2021](https://arxiv.org/pdf/2103.14749.pdf), which randomly samples 1,000 items from the set of flagged items.

`_main_fulltext.csv` files: Full text for each item is included for convenience.

`_cl_rerun.csv` files: Results from re-evaluating Cleanlab items using the revised protocol in Appendix C. These supply Tables 2, 5, 6 and Figure 5, and are structured for easy use with [Cleanlab results](https://github.com/cleanlab/label-errors/tree/main/mturk).

Data at lower levels of granularity is available on request.
